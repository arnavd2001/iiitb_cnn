{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn from scratch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyONJ9d38DuGXLxeXh6qDJO/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnavd2001/iiitb_work/blob/main/nn_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "3EK5oWI_YB48"
      },
      "outputs": [],
      "source": [
        "inputs = [1.2,5.1,2.1]\n",
        "weights = [2.4,4.3,2.5]\n",
        "bias = 3\n",
        "for i in range(len(inputs)):\n",
        "  temp = inputs[i]*weights[i]\n",
        "  output +=temp\n",
        "output += bias\n",
        "\n",
        "#First very basic implementation of a Neuron, we are calculating the output activation value for the given inputs and weights across a neuron with the given bias"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rn we are initialising the weights and values, but lateron the neural netwrk will tweak these values by itself\n",
        "#every neuron will have just one bias value, but it will have a weight for every input value\n",
        "#bias value would also change for every weight set"
      ],
      "metadata": {
        "id": "81F0D0L3YZxb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [1.2,5.1,2.1,3.4]\n",
        "weights = [[3.4,4.3,6.5],[2.4,4.3,3.5],[8.4,6.3,1.5],[2.4,5.3,6.5]]\n",
        "bias = [2,3,0.5,4]\n",
        "for i in range(len(inputs)):\n",
        "  temp+=bias[i]\n",
        "  for j in range(len(weights[i])):\n",
        "    output = inputs[i]*weights[i][j]\n",
        "    temp += output\n",
        "#output = ip * weight +bias\n",
        "#no. of weights and no. of biases would be equal"
      ],
      "metadata": {
        "id": "XYvr_iBSb0Yn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#lets use the dot product, to ease the above opn.\n",
        "inputs = [1.2,5.1,2.1]\n",
        "weights = [2.4,4.3,2.5]\n",
        "bias = [2,3,0.5,4]\n",
        "#the way you pass your first input, is how the return is going to be indexed, so the order of how you define matters\n",
        "#so we pass the weights first, and then inputs, as we want the return to be in the form of the dimensions of weights\n",
        "outp=np.dot(weights,inputs)+bias"
      ],
      "metadata": {
        "id": "lxFn3uCgelIS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implementing biases and weights in a layer of input\n",
        "inputs = [1.2,5.1,2.1]\n",
        "weights = [[3.4,4.3,6.5],[2.4,4.3,3.5],[8.4,6.3,1.5],[2.4,5.3,6.5]]\n",
        "bias = [2,3,0.5,4]\n",
        "output2 = np.dot(weights, inputs) +bias"
      ],
      "metadata": {
        "id": "jdORhWtBkoY0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a layer of input will mean that multiple input values\n",
        "#implementation of 1 layer\n",
        "inputs = [[1.2,5.1,2.1],[2.0,4.8,3.5],[3.4,4.3,2.5],[7.4,6.3,8.5]]\n",
        "weights = [[3.4,4.3,6.5],[2.4,4.3,3.5],[8.4,6.3,1.5],[2.4,5.3,6.5]]\n",
        "bias = [2,3,0.5,4]\n",
        "output2 = np.dot(weights, np.array(inputs).T) +bias"
      ],
      "metadata": {
        "id": "3qCL_W-m-MK_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#implementation of 2 layers\n",
        "#we will have separate weights and biases for the second layer\n",
        "inputs = [[1.2,5.1,2.1],[2.0,4.8,3.5],[3.4,4.3,2.5],[7.4,6.3,8.5]]\n",
        "weights1 = [[3.4,4.3,6.5],[2.4,4.3,3.5],[8.4,6.3,1.5],[2.4,5.3,6.5]]\n",
        "bias1 = [2,3,0.5,4]\n",
        "weights2 = [[7.6,4.7,3.6],[7.8,2.6,5.8],[2.7,8.5,6.3],[2.3,4.6,9.8]]\n",
        "bias2 = [9,7,8.6,2.5]\n",
        "output_layer1 = np.dot(weights1, np.array(inputs).T) +bias1\n",
        "output_layer2 = np.dot(np.array(weights2).T, np.array(output_layer1)) +bias2\n",
        "\n"
      ],
      "metadata": {
        "id": "A4fVIkJb-1OX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DiALGylaA6t1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}